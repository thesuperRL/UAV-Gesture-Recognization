{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-12T17:06:30.819011Z",
     "start_time": "2025-02-12T17:06:29.947823Z"
    }
   },
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "from mediapipe_model_maker import gesture_recognizer\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "mutable default <class 'mediapipe_model_maker.python.core.hyperparameters.BaseHParams'> for field hparams is not allowed: use default_factory",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m tf\u001B[38;5;241m.\u001B[39m__version__\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m2\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mmediapipe_model_maker\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m gesture_recognizer\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mplt\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/UAV-Gesture-Recognization/.venv/lib/python3.12/site-packages/mediapipe_model_maker/__init__.py:19\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mmediapipe_model_maker\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvision\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m image_classifier\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mmediapipe_model_maker\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvision\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m gesture_recognizer\n\u001B[0;32m---> 19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mmediapipe_model_maker\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtext\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m text_classifier\n",
      "File \u001B[0;32m~/PycharmProjects/UAV-Gesture-Recognization/.venv/lib/python3.12/site-packages/mediapipe_model_maker/python/text/text_classifier/__init__.py:19\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mmediapipe_model_maker\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtext\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtext_classifier\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m dataset\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mmediapipe_model_maker\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtext\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtext_classifier\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m model_options\n\u001B[0;32m---> 19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mmediapipe_model_maker\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtext\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtext_classifier\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m model_spec\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mmediapipe_model_maker\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtext\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtext_classifier\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m text_classifier\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mmediapipe_model_maker\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtext\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtext_classifier\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m text_classifier_options\n",
      "File \u001B[0;32m~/PycharmProjects/UAV-Gesture-Recognization/.venv/lib/python3.12/site-packages/mediapipe_model_maker/python/text/text_classifier/model_spec.py:21\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mfunctools\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mmediapipe_model_maker\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m hyperparameters \u001B[38;5;28;01mas\u001B[39;00m hp\n\u001B[0;32m---> 21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mmediapipe_model_maker\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtext\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m bert_model_spec\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mmediapipe_model_maker\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtext\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtext_classifier\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m model_options \u001B[38;5;28;01mas\u001B[39;00m mo\n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m# BERT-based text classifier spec inherited from BertModelSpec\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/UAV-Gesture-Recognization/.venv/lib/python3.12/site-packages/mediapipe_model_maker/python/text/core/bert_model_spec.py:29\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mmediapipe_model_maker\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtext\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m bert_model_options\n\u001B[1;32m     22\u001B[0m _DEFAULT_TFLITE_INPUT_NAME \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     23\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mids\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mserving_default_input_word_ids:0\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmask\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mserving_default_input_mask:0\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     25\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msegment_ids\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mserving_default_input_type_ids:0\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     26\u001B[0m }\n\u001B[0;32m---> 29\u001B[0m \u001B[38;5;129;43m@dataclasses\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataclass\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;43;01mclass\u001B[39;49;00m\u001B[38;5;250;43m \u001B[39;49m\u001B[38;5;21;43;01mBertModelSpec\u001B[39;49;00m\u001B[43m:\u001B[49m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;250;43m  \u001B[39;49m\u001B[38;5;124;43;03m\"\"\"Specification for a BERT model.\u001B[39;49;00m\n\u001B[1;32m     32\u001B[0m \n\u001B[1;32m     33\u001B[0m \u001B[38;5;124;43;03m  See https://arxiv.org/abs/1810.04805 (BERT: Pre-training of Deep Bidirectional\u001B[39;49;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;124;43;03m      name: The name of the object.\u001B[39;49;00m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;124;43;03m  \"\"\"\u001B[39;49;00m\n\u001B[1;32m     47\u001B[0m \u001B[43m  \u001B[49m\u001B[43mhparams\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mhp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mBaseHParams\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mhp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mBaseHParams\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     48\u001B[0m \u001B[43m      \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     49\u001B[0m \u001B[43m      \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     50\u001B[0m \u001B[43m      \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3e-5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     51\u001B[0m \u001B[43m      \u001B[49m\u001B[43mdistribution_strategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmirrored\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/lib/python3.12/dataclasses.py:1268\u001B[0m, in \u001B[0;36mdataclass\u001B[0;34m(cls, init, repr, eq, order, unsafe_hash, frozen, match_args, kw_only, slots, weakref_slot)\u001B[0m\n\u001B[1;32m   1265\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m wrap\n\u001B[1;32m   1267\u001B[0m \u001B[38;5;66;03m# We're called as @dataclass without parens.\u001B[39;00m\n\u001B[0;32m-> 1268\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mwrap\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/lib/python3.12/dataclasses.py:1258\u001B[0m, in \u001B[0;36mdataclass.<locals>.wrap\u001B[0;34m(cls)\u001B[0m\n\u001B[1;32m   1257\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mwrap\u001B[39m(\u001B[38;5;28mcls\u001B[39m):\n\u001B[0;32m-> 1258\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_process_class\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mrepr\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43munsafe_hash\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1259\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mfrozen\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmatch_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkw_only\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mslots\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1260\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mweakref_slot\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/lib/python3.12/dataclasses.py:994\u001B[0m, in \u001B[0;36m_process_class\u001B[0;34m(cls, init, repr, eq, order, unsafe_hash, frozen, match_args, kw_only, slots, weakref_slot)\u001B[0m\n\u001B[1;32m    991\u001B[0m         kw_only \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    992\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    993\u001B[0m         \u001B[38;5;66;03m# Otherwise it's a field of some type.\u001B[39;00m\n\u001B[0;32m--> 994\u001B[0m         cls_fields\u001B[38;5;241m.\u001B[39mappend(\u001B[43m_get_field\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkw_only\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    996\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m cls_fields:\n\u001B[1;32m    997\u001B[0m     fields[f\u001B[38;5;241m.\u001B[39mname] \u001B[38;5;241m=\u001B[39m f\n",
      "File \u001B[0;32m/usr/lib/python3.12/dataclasses.py:852\u001B[0m, in \u001B[0;36m_get_field\u001B[0;34m(cls, a_name, a_type, default_kw_only)\u001B[0m\n\u001B[1;32m    848\u001B[0m \u001B[38;5;66;03m# For real fields, disallow mutable defaults.  Use unhashable as a proxy\u001B[39;00m\n\u001B[1;32m    849\u001B[0m \u001B[38;5;66;03m# indicator for mutability.  Read the __hash__ attribute from the class,\u001B[39;00m\n\u001B[1;32m    850\u001B[0m \u001B[38;5;66;03m# not the instance.\u001B[39;00m\n\u001B[1;32m    851\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m f\u001B[38;5;241m.\u001B[39m_field_type \u001B[38;5;129;01mis\u001B[39;00m _FIELD \u001B[38;5;129;01mand\u001B[39;00m f\u001B[38;5;241m.\u001B[39mdefault\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__hash__\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 852\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmutable default \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(f\u001B[38;5;241m.\u001B[39mdefault)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m for field \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    853\u001B[0m                      \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mf\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is not allowed: use default_factory\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    855\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m f\n",
      "\u001B[0;31mValueError\u001B[0m: mutable default <class 'mediapipe_model_maker.python.core.hyperparameters.BaseHParams'> for field hparams is not allowed: use default_factory"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#dataset_path = \"/mnt/e2/GoogleCVTraining/hagrid-classification-512p\"\n",
    "dataset_path = \"E:\\\\GoogleCVTraining\\\\hagrid-classification-512p\"\n",
    "\n",
    "print(dataset_path)\n",
    "labels = []\n",
    "for i in os.listdir(dataset_path):\n",
    "  if os.path.isdir(os.path.join(dataset_path, i)):\n",
    "    labels.append(i)\n",
    "print(labels)"
   ],
   "id": "e74c9807af27d6ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "NUM_EXAMPLES = 5\n",
    "\n",
    "for label in labels:\n",
    "  label_dir = os.path.join(dataset_path, label)\n",
    "  example_filenames = os.listdir(label_dir)[:NUM_EXAMPLES]\n",
    "  fig, axs = plt.subplots(1, NUM_EXAMPLES, figsize=(10,2))\n",
    "  for i in range(NUM_EXAMPLES):\n",
    "    axs[i].imshow(plt.imread(os.path.join(label_dir, example_filenames[i])))\n",
    "    axs[i].get_xaxis().set_visible(False)\n",
    "    axs[i].get_yaxis().set_visible(False)\n",
    "  fig.suptitle(f'Showing {NUM_EXAMPLES} examples for {label}')\n",
    "\n",
    "plt.show()"
   ],
   "id": "c376ce7b211e23d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data = gesture_recognizer.Dataset.from_folder(\n",
    "    dirname=dataset_path,\n",
    "    hparams=gesture_recognizer.HandDataPreprocessingParams()\n",
    ")\n",
    "train_data, rest_data = data.split(0.8)\n",
    "validation_data, test_data = rest_data.split(0.5)"
   ],
   "id": "3a7c8dbc877e6d1e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
